"""
LCEL SQL íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸

ì´ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ëŠ” LCEL ê¸°ë°˜ SQL ìƒì„± íŒŒì´í”„ë¼ì¸ì˜ 
ì „ì²´ ê¸°ëŠ¥ì„ ê²€ì¦í•©ë‹ˆë‹¤.
"""

import pytest
import asyncio
import json
from typing import Dict, Any, List
from unittest.mock import Mock, patch, AsyncMock

from app.services.lcel_sql_pipeline import (
    LCELSQLPipeline,
    EnhancedSQLGenerationRequest,
    EnhancedSQLPipelineResponse,
    ExecutionStrategy,
    RetryConfig,
    RuleBasedSQLGenerator,
    SQLGenerationResult
)
from app.services.intent_classifier import ClassificationResultDict


class TestRuleBasedSQLGenerator:
    """ê·œì¹™ ê¸°ë°˜ SQL ìƒì„±ê¸° í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def rule_generator(self):
        return RuleBasedSQLGenerator()
    
    @pytest.mark.asyncio
    async def test_simple_query_generation(self, rule_generator):
        """ë‹¨ìˆœ ì¡°íšŒ ì¿¼ë¦¬ ìƒì„± í…ŒìŠ¤íŠ¸"""
        intent_result: ClassificationResultDict = {
            "query_type": {"main_type": "simple_query", "confidence": 0.8, "reasoning": "test"},
            "entities": {},
            "intent_keywords": ["ì¡°íšŒ"],
            "complexity_score": 0.3
        }
        
        result = await rule_generator.generate_sql(intent_result)
        
        assert isinstance(result, SQLGenerationResult)
        assert "SELECT" in result.sql.upper()
        assert result.generation_method == "rule_based"
        assert result.confidence > 0.0
        assert len(result.explanation) > 0
    
    @pytest.mark.asyncio
    async def test_filtering_query_generation(self, rule_generator):
        """í•„í„°ë§ ì¿¼ë¦¬ ìƒì„± í…ŒìŠ¤íŠ¸"""
        intent_result: ClassificationResultDict = {
            "query_type": {"main_type": "filtering", "confidence": 0.9, "reasoning": "test"},
            "entities": {
                "customer_names": ["í™ê¸¸ë™"],
                "dates": ["ìµœê·¼ 30ì¼"]
            },
            "intent_keywords": ["ì°¾ê¸°"],
            "complexity_score": 0.6
        }
        
        result = await rule_generator.generate_sql(intent_result)
        
        assert "WHERE" in result.sql.upper()
        assert result.generation_method == "rule_based"
        assert len(result.parameters) >= 0  # íŒŒë¼ë¯¸í„°ê°€ ìˆì„ ìˆ˜ ìˆìŒ
    
    @pytest.mark.asyncio
    async def test_aggregation_query_generation(self, rule_generator):
        """ì§‘ê³„ ì¿¼ë¦¬ ìƒì„± í…ŒìŠ¤íŠ¸"""
        intent_result: ClassificationResultDict = {
            "query_type": {"main_type": "aggregation", "confidence": 0.95, "reasoning": "test"},
            "entities": {
                "dates": ["ì§€ë‚œ 3ê°œì›”"]
            },
            "intent_keywords": ["ê°œìˆ˜", "ìˆ˜"],
            "complexity_score": 0.7
        }
        
        result = await rule_generator.generate_sql(intent_result)
        
        assert any(agg in result.sql.upper() for agg in ["COUNT", "SUM", "AVG", "MAX", "MIN"])
        assert result.generation_method == "rule_based"
    
    @pytest.mark.asyncio
    async def test_join_query_generation(self, rule_generator):
        """ì¡°ì¸ ì¿¼ë¦¬ ìƒì„± í…ŒìŠ¤íŠ¸"""
        intent_result: ClassificationResultDict = {
            "query_type": {"main_type": "join", "confidence": 0.85, "reasoning": "test"},
            "entities": {},
            "intent_keywords": ["ê´€ë ¨", "ì—°ê²°"],
            "complexity_score": 0.8
        }
        
        result = await rule_generator.generate_sql(intent_result)
        
        assert "JOIN" in result.sql.upper()
        assert result.generation_method == "rule_based"


class TestLCELSQLPipeline:
    """LCEL SQL íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def pipeline(self):
        """íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤ í”½ìŠ¤ì²˜"""
        return LCELSQLPipeline()
    
    @pytest.mark.asyncio
    async def test_pipeline_initialization(self, pipeline):
        """íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        assert pipeline.llm_manager is not None
        assert pipeline.chat_client is not None
        assert pipeline.rule_generator is not None
        assert pipeline.default_retry_config is not None
        
        # ì²´ì¸ë“¤ì´ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
        assert pipeline.intent_chain is not None
        assert pipeline.llm_sql_chain is not None
        assert pipeline.rule_sql_chain is not None
        assert pipeline.validation_chain is not None
        assert pipeline.fallback_chain is not None
        assert pipeline.hybrid_chain is not None
        assert pipeline.pipeline_chain is not None
    
    @pytest.mark.asyncio
    @patch('app.services.lcel_sql_pipeline.korean_intent_classifier')
    async def test_simple_sql_generation(self, mock_classifier, pipeline):
        """ê°„ë‹¨í•œ SQL ìƒì„± í…ŒìŠ¤íŠ¸"""
        # Mock ì˜ë„ ë¶„ë¥˜ ê²°ê³¼
        mock_classifier.classify.return_value = {
            "query_type": {"main_type": "simple_query", "confidence": 0.8, "reasoning": "test"},
            "entities": {"customer_names": ["í™ê¸¸ë™"]},
            "intent_keywords": ["ì •ë³´"],
            "complexity_score": 0.4
        }
        
        request = EnhancedSQLGenerationRequest(
            query="í™ê¸¸ë™ ê³ ê° ì •ë³´ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”",
            strategy=ExecutionStrategy.RULE_ONLY  # í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ê·œì¹™ ê¸°ë°˜ë§Œ ì‚¬ìš©
        )
        
        result = await pipeline.generate_sql(request)
        
        assert isinstance(result, EnhancedSQLPipelineResponse)
        assert result.success is True
        assert result.sql_result is not None
        assert "SELECT" in result.sql_result.sql.upper()
        assert result.intent_analysis is not None
        assert result.metrics is not None
    
    @pytest.mark.asyncio
    @patch('app.services.lcel_sql_pipeline.korean_intent_classifier')
    async def test_different_strategies(self, mock_classifier, pipeline):
        """ë‹¤ì–‘í•œ ì‹¤í–‰ ì „ëµ í…ŒìŠ¤íŠ¸"""
        # Mock ì˜ë„ ë¶„ë¥˜ ê²°ê³¼
        mock_classifier.classify.return_value = {
            "query_type": {"main_type": "aggregation", "confidence": 0.9, "reasoning": "test"},
            "entities": {},
            "intent_keywords": ["ê°œìˆ˜"],
            "complexity_score": 0.6
        }
        
        strategies = [
            ExecutionStrategy.RULE_ONLY,
            ExecutionStrategy.LLM_FIRST,
            # ExecutionStrategy.HYBRID,  # LLM ëª¨í‚¹ì´ ë³µì¡í•˜ë¯€ë¡œ ì œì™¸
        ]
        
        for strategy in strategies:
            request = EnhancedSQLGenerationRequest(
                query="ê³ ê° ìˆ˜ë¥¼ ì„¸ì–´ì£¼ì„¸ìš”",
                strategy=strategy
            )
            
            result = await pipeline.generate_sql(request)
            
            assert result.success is True
            assert result.sql_result is not None
            assert result.metrics["strategy_used"] == strategy
    
    @pytest.mark.asyncio
    @patch('app.services.lcel_sql_pipeline.korean_intent_classifier')
    async def test_retry_configuration(self, mock_classifier, pipeline):
        """ì¬ì‹œë„ ì„¤ì • í…ŒìŠ¤íŠ¸"""
        # Mock ì˜ë„ ë¶„ë¥˜ ê²°ê³¼
        mock_classifier.classify.return_value = {
            "query_type": {"main_type": "simple_query", "confidence": 0.5, "reasoning": "test"},
            "entities": {},
            "intent_keywords": [],
            "complexity_score": 0.2
        }
        
        # ì»¤ìŠ¤í…€ ì¬ì‹œë„ ì„¤ì •
        retry_config = RetryConfig(
            max_attempts=2,
            base_delay=0.1,
            max_delay=1.0,
            exponential_base=2.0
        )
        
        request = EnhancedSQLGenerationRequest(
            query="í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬",
            strategy=ExecutionStrategy.RULE_ONLY,
            retry_config=retry_config,
            timeout_seconds=10.0
        )
        
        result = await pipeline.generate_sql(request)
        
        # ê·œì¹™ ê¸°ë°˜ì´ë¯€ë¡œ ì„±ê³µí•´ì•¼ í•¨
        assert result.success is True
    
    @pytest.mark.asyncio
    @patch('app.services.lcel_sql_pipeline.korean_intent_classifier')
    async def test_error_handling(self, mock_classifier, pipeline):
        """ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # Mockì—ì„œ ì˜ˆì™¸ ë°œìƒí•˜ë„ë¡ ì„¤ì •
        mock_classifier.classify.side_effect = Exception("í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜")
        
        request = EnhancedSQLGenerationRequest(
            query="ì˜¤ë¥˜ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬",
            strategy=ExecutionStrategy.RULE_ONLY
        )
        
        result = await pipeline.generate_sql(request)
        
        # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê¸°ë³¸ ì‘ë‹µì„ ë°˜í™˜í•´ì•¼ í•¨
        assert result.success is False
        assert result.error_message is not None
        assert "í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜" in result.error_message or "pipeline_error" in result.sql_result.sql
    
    @pytest.mark.asyncio
    @patch('app.services.lcel_sql_pipeline.korean_intent_classifier')
    async def test_streaming_functionality(self, mock_classifier, pipeline):
        """ìŠ¤íŠ¸ë¦¬ë° ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        # Mock ì˜ë„ ë¶„ë¥˜ ê²°ê³¼
        mock_classifier.classify.return_value = {
            "query_type": {"main_type": "simple_query", "confidence": 0.8, "reasoning": "test"},
            "entities": {},
            "intent_keywords": ["ì¡°íšŒ"],
            "complexity_score": 0.3
        }
        
        request = EnhancedSQLGenerationRequest(
            query="ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸",
            strategy=ExecutionStrategy.RULE_ONLY,
            enable_streaming=True,
            timeout_seconds=5.0
        )
        
        events = []
        async for event in pipeline.generate_sql_streaming(request):
            events.append(event)
            
            # ë¬´í•œ ë£¨í”„ ë°©ì§€
            if len(events) > 10:
                break
        
        # ìµœì†Œí•œ ì‹œì‘ê³¼ ì™„ë£Œ ì´ë²¤íŠ¸ê°€ ìˆì–´ì•¼ í•¨
        assert len(events) >= 1
        
        # ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ëŠ” ì™„ë£Œ ì´ë²¤íŠ¸ì—¬ì•¼ í•¨
        if events:
            last_event = events[-1]
            assert last_event.get("type") in ["pipeline_complete", "complete"]
    
    @pytest.mark.asyncio
    @patch('app.services.lcel_sql_pipeline.korean_intent_classifier')
    @patch('app.services.lcel_sql_pipeline.sql_validator')
    async def test_sql_validation_chain(self, mock_validator, mock_classifier, pipeline):
        """SQL ê²€ì¦ ì²´ì¸ í…ŒìŠ¤íŠ¸"""
        # Mock ì„¤ì •
        mock_classifier.classify.return_value = {
            "query_type": {"main_type": "simple_query", "confidence": 0.8, "reasoning": "test"},
            "entities": {},
            "intent_keywords": [],
            "complexity_score": 0.3
        }
        
        # ì•ˆì „í•˜ì§€ ì•Šì€ ì¿¼ë¦¬ë¡œ ì‹œë®¬ë ˆì´ì…˜
        mock_validator.validate_query_safety.return_value = False
        
        request = EnhancedSQLGenerationRequest(
            query="ìœ„í—˜í•œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸",
            strategy=ExecutionStrategy.RULE_ONLY
        )
        
        result = await pipeline.generate_sql(request)
        
        # ê²€ì¦ì´ ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ì¿¼ë¦¬ë¡œ ëŒ€ì²´ë˜ì–´ ì„±ê³µí•´ì•¼ í•¨
        assert result.success is True
        assert "validation_failed" in result.sql_result.sql or result.sql_result.confidence < 0.5


class TestRetryLogic:
    """ì¬ì‹œë„ ë¡œì§ í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    async def test_exponential_backoff_success(self):
        """ì§€ìˆ˜ ë°±ì˜¤í”„ ì„±ê³µ ì¼€ì´ìŠ¤"""
        from app.services.lcel_sql_pipeline import exponential_backoff_retry
        
        retry_config = RetryConfig(max_attempts=3, base_delay=0.01, exponential_base=2.0)
        
        call_count = 0
        
        @exponential_backoff_retry(retry_config)
        async def mock_function():
            nonlocal call_count
            call_count += 1
            if call_count < 2:  # ì²« ë²ˆì§¸ í˜¸ì¶œì€ ì‹¤íŒ¨
                raise Exception("RateLimitError: í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜")
            return "ì„±ê³µ"
        
        result = await mock_function()
        
        assert result == "ì„±ê³µ"
        assert call_count == 2  # í•œ ë²ˆ ì‹¤íŒ¨ í›„ ì„±ê³µ
    
    @pytest.mark.asyncio
    async def test_exponential_backoff_max_attempts(self):
        """ìµœëŒ€ ì‹œë„ íšŸìˆ˜ í…ŒìŠ¤íŠ¸"""
        from app.services.lcel_sql_pipeline import exponential_backoff_retry
        
        retry_config = RetryConfig(max_attempts=2, base_delay=0.01, exponential_base=2.0)
        
        call_count = 0
        
        @exponential_backoff_retry(retry_config)
        async def mock_function():
            nonlocal call_count
            call_count += 1
            raise Exception("RateLimitError: ê³„ì† ì‹¤íŒ¨")
        
        with pytest.raises(Exception, match="ê³„ì† ì‹¤íŒ¨"):
            await mock_function()
        
        assert call_count == 2  # ìµœëŒ€ ì‹œë„ íšŸìˆ˜ë§Œí¼ í˜¸ì¶œ
    
    @pytest.mark.asyncio
    async def test_non_retriable_exception(self):
        """ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì˜ˆì™¸ í…ŒìŠ¤íŠ¸"""
        from app.services.lcel_sql_pipeline import exponential_backoff_retry
        
        retry_config = RetryConfig(max_attempts=3, retriable_exceptions=["RateLimitError"])
        
        call_count = 0
        
        @exponential_backoff_retry(retry_config)
        async def mock_function():
            nonlocal call_count
            call_count += 1
            raise ValueError("ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜")
        
        with pytest.raises(ValueError, match="ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜"):
            await mock_function()
        
        assert call_count == 1  # í•œ ë²ˆë§Œ í˜¸ì¶œë˜ê³  ì¬ì‹œë„ ì•ˆë¨


class TestSQLGenerationRequest:
    """SQL ìƒì„± ìš”ì²­ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    
    def test_valid_request_creation(self):
        """ìœ íš¨í•œ ìš”ì²­ ìƒì„± í…ŒìŠ¤íŠ¸"""
        request = EnhancedSQLGenerationRequest(
            query="ê³ ê° ì •ë³´ë¥¼ ì¡°íšŒí•´ì£¼ì„¸ìš”",
            strategy=ExecutionStrategy.LLM_FIRST,
            enable_streaming=False,
            timeout_seconds=30.0
        )
        
        assert request.query == "ê³ ê° ì •ë³´ë¥¼ ì¡°íšŒí•´ì£¼ì„¸ìš”"
        assert request.strategy == ExecutionStrategy.LLM_FIRST
        assert request.enable_streaming is False
        assert request.timeout_seconds == 30.0
    
    def test_default_values(self):
        """ê¸°ë³¸ê°’ ì„¤ì • í…ŒìŠ¤íŠ¸"""
        request = EnhancedSQLGenerationRequest(query="í…ŒìŠ¤íŠ¸")
        
        assert request.strategy == ExecutionStrategy.LLM_FIRST
        assert request.enable_streaming is False
        assert request.enable_caching is True
        assert request.retry_config is None
        assert request.timeout_seconds == 30.0
    
    def test_invalid_query_length(self):
        """ì¿¼ë¦¬ ê¸¸ì´ ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        with pytest.raises(Exception):  # ValidationError
            EnhancedSQLGenerationRequest(query="")  # ë¹ˆ ì¿¼ë¦¬
        
        with pytest.raises(Exception):  # ValidationError
            EnhancedSQLGenerationRequest(query="x" * 2001)  # ë„ˆë¬´ ê¸´ ì¿¼ë¦¬


class TestPipelineMetrics:
    """íŒŒì´í”„ë¼ì¸ ë©”íŠ¸ë¦­ í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    @patch('app.services.lcel_sql_pipeline.korean_intent_classifier')
    async def test_metrics_collection(self, mock_classifier):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸"""
        # Mock ì„¤ì •
        mock_classifier.classify.return_value = {
            "query_type": {"main_type": "simple_query", "confidence": 0.8, "reasoning": "test"},
            "entities": {},
            "intent_keywords": [],
            "complexity_score": 0.3
        }
        
        pipeline = LCELSQLPipeline()
        request = EnhancedSQLGenerationRequest(
            query="ë©”íŠ¸ë¦­ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬",
            strategy=ExecutionStrategy.RULE_ONLY
        )
        
        result = await pipeline.generate_sql(request)
        
        assert result.metrics is not None
        assert "total_duration" in result.metrics
        assert "strategy_used" in result.metrics
        assert "generation_method" in result.metrics
        
        # ì‹¤í–‰ ì‹œê°„ì´ ì–‘ìˆ˜ì—¬ì•¼ í•¨
        assert result.metrics["total_duration"] >= 0.0


# í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰ìš© í—¬í¼ í•¨ìˆ˜ë“¤

async def run_pipeline_performance_test(pipeline: LCELSQLPipeline, num_requests: int = 5):
    """íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    import time
    
    requests = [
        EnhancedSQLGenerationRequest(
            query=f"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ {i}",
            strategy=ExecutionStrategy.RULE_ONLY
        )
        for i in range(num_requests)
    ]
    
    start_time = time.time()
    
    # ë™ì‹œ ì‹¤í–‰
    with patch('app.services.lcel_sql_pipeline.korean_intent_classifier') as mock_classifier:
        mock_classifier.classify.return_value = {
            "query_type": {"main_type": "simple_query", "confidence": 0.8, "reasoning": "test"},
            "entities": {},
            "intent_keywords": [],
            "complexity_score": 0.3
        }
        
        tasks = [pipeline.generate_sql(req) for req in requests]
        results = await asyncio.gather(*tasks, return_exceptions=True)
    
    total_time = time.time() - start_time
    
    # ê²°ê³¼ ë¶„ì„
    successful_results = [r for r in results if isinstance(r, EnhancedSQLPipelineResponse) and r.success]
    failed_results = [r for r in results if not (isinstance(r, EnhancedSQLPipelineResponse) and r.success)]
    
    return {
        "total_requests": num_requests,
        "successful": len(successful_results),
        "failed": len(failed_results),
        "total_time": total_time,
        "avg_time_per_request": total_time / num_requests,
        "throughput": num_requests / total_time
    }


@pytest.mark.asyncio
@pytest.mark.performance
async def test_pipeline_performance():
    """íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë§ˆí¬)"""
    pipeline = LCELSQLPipeline()
    
    performance_results = await run_pipeline_performance_test(pipeline, num_requests=3)
    
    # ì„±ëŠ¥ ê¸°ì¤€ ê²€ì¦ (ì¡°ì • ê°€ëŠ¥)
    assert performance_results["successful"] >= performance_results["total_requests"] * 0.8  # 80% ì„±ê³µë¥ 
    assert performance_results["avg_time_per_request"] < 10.0  # í‰ê·  10ì´ˆ ì´ë‚´
    assert performance_results["throughput"] > 0.1  # ì´ˆë‹¹ 0.1 ìš”ì²­ ì´ìƒ
    
    print(f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼: {performance_results}")


# ì‹¤ì œ E2E í…ŒìŠ¤íŠ¸ (API ì—”ë“œí¬ì¸íŠ¸ í¬í•¨)
@pytest.mark.asyncio
@pytest.mark.integration
async def test_api_endpoint_integration():
    """API ì—”ë“œí¬ì¸íŠ¸ í†µí•© í…ŒìŠ¤íŠ¸"""
    # ì´ í…ŒìŠ¤íŠ¸ëŠ” ì‹¤ì œ FastAPI ì•±ì´ ì‹¤í–‰ëœ ìƒíƒœì—ì„œ í…ŒìŠ¤íŠ¸
    # ì—¬ê¸°ì„œëŠ” êµ¬ì¡°ë§Œ ì œê³µí•˜ê³ , ì‹¤ì œ êµ¬í˜„ì€ ë³„ë„ í…ŒìŠ¤íŠ¸ íŒŒì¼ì—ì„œ
    pass


if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ìš© í…ŒìŠ¤íŠ¸
    import sys
    import os
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))
    
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    async def main():
        print("ğŸ§ª LCEL SQL íŒŒì´í”„ë¼ì¸ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        
        try:
            pipeline = LCELSQLPipeline()
            print("âœ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì„±ê³µ")
            
            # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            perf_results = await run_pipeline_performance_test(pipeline, 2)
            print(f"âœ… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {perf_results}")
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    asyncio.run(main())