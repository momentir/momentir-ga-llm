#!/usr/bin/env python3
"""
Azure OpenAI ë°°í¬ ëª¨ë¸ ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸
ë°°í¬ëœ ëª¨ë¸ë“¤ì„ í™•ì¸í•˜ê³  ì—°ê²°ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import os
import asyncio
import sys
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

async def debug_azure_deployments():
    """Azure OpenAI ë°°í¬ ëª¨ë¸ë“¤ì„ ë””ë²„ê¹…í•©ë‹ˆë‹¤."""
    
    try:
        import openai
    except ImportError:
        print("âŒ openai ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   pip install openai ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return False
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-01")
    chat_deployment = os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT_NAME")
    
    # ì„ë² ë”© ì „ìš© ë¦¬ì†ŒìŠ¤ ì„¤ì •
    embedding_endpoint = os.getenv("AZURE_EMBEDDING_ENDPOINT")
    embedding_api_key = os.getenv("AZURE_EMBEDDING_API_KEY")
    embedding_api_version = os.getenv("AZURE_EMBEDDING_API_VERSION", "2024-02-01")
    embedding_deployment = os.getenv("AZURE_EMBEDDING_DEPLOYMENT_NAME")
    
    print("ğŸ” Azure OpenAI ì„¤ì • ì •ë³´:")
    print(f"   Chat Endpoint: {endpoint}")
    print(f"   Chat API Version: {api_version}")
    print(f"   Chat Deployment: {chat_deployment}")
    print()
    print("ğŸ” Azure ì„ë² ë”© ì „ìš© ë¦¬ì†ŒìŠ¤ ì„¤ì •:")
    print(f"   Embedding Endpoint: {embedding_endpoint}")
    print(f"   Embedding API Version: {embedding_api_version}")
    print(f"   Embedding Deployment: {embedding_deployment}")
    print()
    
    if not all([api_key, endpoint, chat_deployment]):
        print("âŒ í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    try:
        client = openai.AsyncAzureOpenAI(
            api_key=api_key,
            azure_endpoint=endpoint,
            api_version=api_version
        )
        print("âœ… Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì„±ê³µ")
    except Exception as e:
        print(f"âŒ Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return False
    
    # ë°°í¬ëœ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹œë„
    print()
    print("ğŸ“‹ ë°°í¬ëœ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹œë„:")
    try:
        # Azure REST APIë¥¼ í†µí•´ ë°°í¬ ëª©ë¡ ì¡°íšŒ
        import httpx
        
        headers = {
            "api-key": api_key,
            "Content-Type": "application/json"
        }
        
        # ë°°í¬ ëª©ë¡ ì¡°íšŒ URL
        deployments_url = f"{endpoint.rstrip('/')}/openai/deployments?api-version={api_version}"
        
        async with httpx.AsyncClient() as http_client:
            response = await http_client.get(deployments_url, headers=headers)
            
            if response.status_code == 200:
                deployments = response.json()
                if deployments.get("data"):
                    print("   âœ… ë°°í¬ëœ ëª¨ë¸ë“¤:")
                    for deployment in deployments["data"]:
                        model_name = deployment.get("model", "unknown")
                        deployment_name = deployment.get("id", "unknown")
                        status = deployment.get("status", "unknown")
                        print(f"      â€¢ {deployment_name} ({model_name}) - {status}")
                else:
                    print("   âš ï¸  ë°°í¬ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print(f"   âŒ ë°°í¬ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {response.status_code}")
                
    except Exception as e:
        print(f"   âš ï¸  ë°°í¬ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
    
    print()
    
    # ì¼ë°˜ì ì¸ ë°°í¬ëª…ë“¤ì„ ì‹œë„í•´ë´…ë‹ˆë‹¤
    common_chat_deployments = [
        chat_deployment,  # ì„¤ì •ëœ ë°°í¬ëª…
        "gpt-4",
        "gpt-4-turbo", 
        "gpt-4o",
        "gpt-35-turbo",
        "gpt-3.5-turbo"
    ]
    
    print("ğŸ§ª Chat ëª¨ë¸ ë°°í¬ í…ŒìŠ¤íŠ¸:")
    working_chat_deployment = None
    
    for deployment in common_chat_deployments:
        if not deployment:
            continue
            
        try:
            print(f"   â¤ í…ŒìŠ¤íŠ¸ ì¤‘: {deployment}")
            response = await client.chat.completions.create(
                model=deployment,
                messages=[
                    {"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”"}
                ],
                max_tokens=10
            )
            
            result = response.choices[0].message.content
            print(f"   âœ… ì„±ê³µ: {deployment} - ì‘ë‹µ: {result}")
            working_chat_deployment = deployment
            break
            
        except Exception as e:
            print(f"   âŒ ì‹¤íŒ¨: {deployment} - {str(e)}")
    
    print()
    
    # ì„ë² ë”© ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ì „ìš© ë¦¬ì†ŒìŠ¤ ì‚¬ìš©)
    print("ğŸ§ª Embedding ëª¨ë¸ ë°°í¬ í…ŒìŠ¤íŠ¸ (ì „ìš© ë¦¬ì†ŒìŠ¤):")
    working_embedding_deployment = None
    
    if embedding_endpoint and embedding_api_key and embedding_deployment:
        try:
            # ì„ë² ë”© ì „ìš© í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            embedding_client = openai.AsyncAzureOpenAI(
                api_key=embedding_api_key,
                azure_endpoint=embedding_endpoint,
                api_version=embedding_api_version
            )
            
            print(f"   â¤ í…ŒìŠ¤íŠ¸ ì¤‘: {embedding_deployment}")
            response = await embedding_client.embeddings.create(
                model=embedding_deployment,
                input="í…ŒìŠ¤íŠ¸"
            )
            
            embedding = response.data[0].embedding
            print(f"   âœ… ì„±ê³µ: {embedding_deployment} - ì°¨ì›: {len(embedding)}")
            working_embedding_deployment = embedding_deployment
            
        except Exception as e:
            print(f"   âŒ ì‹¤íŒ¨: {embedding_deployment} - {str(e)}")
    else:
        print("   âš ï¸  ì„ë² ë”© ì „ìš© ë¦¬ì†ŒìŠ¤ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    print()
    
    # ê²°ê³¼ ìš”ì•½
    if working_chat_deployment or working_embedding_deployment:
        print("ğŸ‰ ì‘ë™í•˜ëŠ” ë°°í¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
        
        if working_chat_deployment:
            print(f"   Chat ëª¨ë¸: {working_chat_deployment}")
            
        if working_embedding_deployment:
            print(f"   Embedding ëª¨ë¸: {working_embedding_deployment}")
        
        print()
        print("ğŸ’¡ .env íŒŒì¼ì„ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •í•˜ì„¸ìš”:")
        
        if working_chat_deployment and working_chat_deployment != chat_deployment:
            print(f"   AZURE_OPENAI_CHAT_DEPLOYMENT_NAME={working_chat_deployment}")
            
        if working_embedding_deployment and working_embedding_deployment != embedding_deployment:
            print(f"   AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME={working_embedding_deployment}")
        
        return True
    else:
        print("âŒ ì‘ë™í•˜ëŠ” ë°°í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print()
        print("ğŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²•:")
        print("   1. Azure Portalì—ì„œ OpenAI ë¦¬ì†ŒìŠ¤ í™•ì¸")
        print("   2. ëª¨ë¸ ë°°í¬ ìƒíƒœ í™•ì¸")
        print("   3. API í‚¤ ë° ì—”ë“œí¬ì¸íŠ¸ í™•ì¸")
        print("   4. ë°°í¬ëª…ì´ ì •í™•í•œì§€ í™•ì¸")
        
        return False

if __name__ == "__main__":
    print("ğŸ” Azure OpenAI ë°°í¬ ë””ë²„ê¹…")
    print("=" * 40)
    print()
    
    success = asyncio.run(debug_azure_deployments())
    
    if not success:
        sys.exit(1)
    
    print()
    print("âœ… ë””ë²„ê¹… ì™„ë£Œ!")