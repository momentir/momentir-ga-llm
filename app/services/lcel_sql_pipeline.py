"""
LangChain Expression Language (LCEL) ê¸°ë°˜ ê³ ê¸‰ SQL ìƒì„± íŒŒì´í”„ë¼ì¸

ì´ ëª¨ë“ˆì€ ìì—°ì–´ë¥¼ SQLë¡œ ë³€í™˜í•˜ëŠ” ê³ ê¸‰ íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤:
- ìì—°ì–´ â†’ ì˜ë„ íŒŒì‹± â†’ SQL ìƒì„± â†’ ê²€ì¦ ì²´ì¸
- Fallback ì²´ì¸ (LLM ì‹¤íŒ¨ ì‹œ ê·œì¹™ ê¸°ë°˜)
- Retry ë¡œì§ with exponential backoff 
- LangSmith ì¶”ì  í†µí•©
- ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì§€ì›
"""

import logging
import asyncio
import time
import json
from typing import List, Dict, Any, Optional, Union, AsyncIterator, Tuple
from enum import Enum
from datetime import datetime
from dataclasses import dataclass
from functools import wraps
import random

from pydantic import BaseModel, Field, ConfigDict
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser
from langchain_core.runnables import (
    RunnableParallel, RunnablePassthrough, RunnableLambda, 
    RunnableBranch, RunnableConfig, RunnableWithFallbacks
)
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.exceptions import OutputParserException
from langchain_core.callbacks import AsyncCallbackHandler, BaseCallbackHandler
from langchain_core.tracers.langchain import LangChainTracer

from app.utils.langsmith_config import langsmith_manager, trace_llm_call
from app.services.intent_classifier import korean_intent_classifier, ClassificationResultDict
from app.services.sql_validator import sql_validator
from app.prompts.nl_search_prompts import nl_prompt_manager
from app.utils.llm_client import LLMClientManager
from app.database import read_only_db_manager

logger = logging.getLogger(__name__)


class PipelineStage(str, Enum):
    """íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ë‹¨ê³„"""
    INPUT_VALIDATION = "input_validation"
    INTENT_PARSING = "intent_parsing"
    SQL_GENERATION = "sql_generation"
    SQL_VALIDATION = "sql_validation"
    SQL_EXECUTION = "sql_execution"
    RESULT_FORMATTING = "result_formatting"
    ERROR_HANDLING = "error_handling"


class ExecutionStrategy(str, Enum):
    """ì‹¤í–‰ ì „ëµ"""
    LLM_FIRST = "llm_first"      # LLM ìš°ì„ , ì‹¤íŒ¨ì‹œ ê·œì¹™ ê¸°ë°˜
    RULE_FIRST = "rule_first"    # ê·œì¹™ ê¸°ë°˜ ìš°ì„ , ì‹¤íŒ¨ì‹œ LLM
    HYBRID = "hybrid"            # ë³‘ë ¬ ì‹¤í–‰ í›„ ê²°ê³¼ ë¹„êµ
    LLM_ONLY = "llm_only"        # LLMë§Œ ì‚¬ìš©
    RULE_ONLY = "rule_only"      # ê·œì¹™ ê¸°ë°˜ë§Œ ì‚¬ìš©


class RetryConfig(BaseModel):
    """ì¬ì‹œë„ ì„¤ì •"""
    max_attempts: int = Field(default=3, ge=1, le=10)
    base_delay: float = Field(default=1.0, gt=0)
    max_delay: float = Field(default=60.0, gt=0)
    exponential_base: float = Field(default=2.0, gt=1)
    jitter: bool = Field(default=True)
    retriable_exceptions: List[str] = Field(default_factory=lambda: [
        "RateLimitError", "APITimeoutError", "APIConnectionError", 
        "InternalServerError", "ServiceUnavailableError"
    ])


@dataclass
class PipelineMetrics:
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë©”íŠ¸ë¦­"""
    stage_timings: Dict[str, float]
    total_duration: float
    retry_counts: Dict[str, int]
    fallback_used: bool
    llm_calls_count: int
    cache_hits: int
    success: bool
    error_message: Optional[str] = None


class StreamingCallbackHandler(AsyncCallbackHandler):
    """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìœ„í•œ ì½œë°± í•¸ë“¤ëŸ¬"""
    
    def __init__(self, stream_queue: asyncio.Queue):
        self.stream_queue = stream_queue
        self.current_stage = ""
        
    async def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs) -> None:
        await self.stream_queue.put({
            "type": "llm_start",
            "stage": self.current_stage,
            "timestamp": time.time()
        })
    
    async def on_llm_new_token(self, token: str, **kwargs) -> None:
        await self.stream_queue.put({
            "type": "token",
            "content": token,
            "stage": self.current_stage,
            "timestamp": time.time()
        })
    
    async def on_llm_end(self, response, **kwargs) -> None:
        await self.stream_queue.put({
            "type": "llm_end",
            "stage": self.current_stage,
            "timestamp": time.time()
        })
    
    async def on_chain_start(self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs) -> None:
        chain_name = serialized.get("name", "unknown")
        self.current_stage = chain_name
        await self.stream_queue.put({
            "type": "stage_start",
            "stage": chain_name,
            "timestamp": time.time()
        })
    
    async def on_chain_end(self, outputs: Dict[str, Any], **kwargs) -> None:
        await self.stream_queue.put({
            "type": "stage_end",
            "stage": self.current_stage,
            "timestamp": time.time()
        })


class EnhancedSQLGenerationRequest(BaseModel):
    """í–¥ìƒëœ SQL ìƒì„± ìš”ì²­"""
    model_config = ConfigDict(str_strip_whitespace=True)
    
    query: str = Field(..., description="ìì—°ì–´ ì¿¼ë¦¬", min_length=1, max_length=2000)
    context: Optional[Dict[str, Any]] = Field(default=None, description="ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸")
    strategy: ExecutionStrategy = Field(default=ExecutionStrategy.LLM_FIRST)
    enable_streaming: bool = Field(default=False)
    enable_caching: bool = Field(default=True)
    retry_config: Optional[RetryConfig] = Field(default=None)
    timeout_seconds: float = Field(default=30.0, gt=0)
    
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "query": "ì§€ë‚œ 3ê°œì›”ê°„ ê°€ì…í•œ 30ëŒ€ ê³ ê°ë“¤ì˜ í‰ê·  ë³´í—˜ë£Œ",
                "context": {"user_id": "123", "department": "sales"},
                "strategy": "llm_first",
                "enable_streaming": False,
                "timeout_seconds": 30.0
            }
        }
    )


class SQLGenerationResult(BaseModel):
    """SQL ìƒì„± ê²°ê³¼"""
    model_config = ConfigDict()
    
    sql: str = Field(..., description="ìƒì„±ëœ SQL")
    parameters: Dict[str, Any] = Field(default_factory=dict)
    explanation: str = Field(..., description="ì¿¼ë¦¬ ì„¤ëª…")
    confidence: float = Field(default=0.0, ge=0.0, le=1.0)
    complexity_score: float = Field(default=0.0, ge=0.0, le=1.0)
    estimated_rows: Optional[int] = Field(default=None)
    estimated_execution_time: Optional[float] = Field(default=None)
    
    # ë©”íƒ€ë°ì´í„°
    generation_method: str = Field(default="llm")  # "llm", "rule_based", "hybrid"
    fallback_used: bool = Field(default=False)
    cache_hit: bool = Field(default=False)
    
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "sql": "SELECT AVG(premium_amount) FROM customers WHERE age_range = '30-39' AND created_at >= '2024-05-01'",
                "parameters": {"age_range": "30-39", "start_date": "2024-05-01"},
                "explanation": "30ëŒ€ ê³ ê°ë“¤ì˜ í‰ê·  ë³´í—˜ë£Œë¥¼ ê³„ì‚°í•˜ëŠ” ì¿¼ë¦¬ì…ë‹ˆë‹¤.",
                "confidence": 0.92,
                "complexity_score": 0.6,
                "generation_method": "llm"
            }
        }
    )


class EnhancedSQLPipelineResponse(BaseModel):
    """í–¥ìƒëœ SQL íŒŒì´í”„ë¼ì¸ ì‘ë‹µ"""
    model_config = ConfigDict()
    
    # ì˜ë„ ë¶„ì„ ê²°ê³¼
    intent_analysis: ClassificationResultDict
    
    # SQL ìƒì„± ê²°ê³¼
    sql_result: SQLGenerationResult
    
    # ì‹¤í–‰ ê²°ê³¼ (ì„ íƒì )
    execution_data: Optional[List[Dict[str, Any]]] = Field(default=None)
    execution_success: bool = Field(default=False)
    
    # ë©”íŠ¸ë¦­
    metrics: Optional[Dict[str, Any]] = Field(default=None)
    
    # ì „ì²´ ì„±ê³µ ì—¬ë¶€
    success: bool = Field(default=True)
    error_message: Optional[str] = Field(default=None)
    
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "intent_analysis": {
                    "query_type": {"main_type": "aggregation", "confidence": 0.9},
                    "entities": {"dates": ["ì§€ë‚œ 3ê°œì›”"], "amounts": ["í‰ê· "]},
                    "complexity_score": 0.7
                },
                "sql_result": {
                    "sql": "SELECT AVG(premium_amount) FROM customers WHERE created_at >= '2024-05-01'",
                    "explanation": "ì§€ë‚œ 3ê°œì›”ê°„ ê°€ì… ê³ ê°ë“¤ì˜ í‰ê·  ë³´í—˜ë£Œ",
                    "confidence": 0.92,
                    "generation_method": "llm"
                },
                "success": True
            }
        }
    )


def exponential_backoff_retry(retry_config: RetryConfig):
    """ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            last_exception = None
            
            for attempt in range(retry_config.max_attempts):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    
                    # ì¬ì‹œë„ ê°€ëŠ¥í•œ ì˜ˆì™¸ì¸ì§€ í™•ì¸
                    if not any(exc_type in str(type(e).__name__) for exc_type in retry_config.retriable_exceptions):
                        logger.info(f"ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì˜ˆì™¸ ë°œìƒ: {type(e).__name__}")
                        raise
                    
                    # ë§ˆì§€ë§‰ ì‹œë„ì¸ ê²½ìš° ì˜ˆì™¸ ë°œìƒ
                    if attempt == retry_config.max_attempts - 1:
                        break
                    
                    # ì§€ìˆ˜ ë°±ì˜¤í”„ ê³„ì‚°
                    delay = min(
                        retry_config.base_delay * (retry_config.exponential_base ** attempt),
                        retry_config.max_delay
                    )
                    
                    # ì§€í„° ì¶”ê°€
                    if retry_config.jitter:
                        delay *= (0.5 + random.random() * 0.5)
                    
                    logger.warning(f"ì¬ì‹œë„ {attempt + 1}/{retry_config.max_attempts}: {delay:.2f}ì´ˆ í›„ ì¬ì‹œë„ - {e}")
                    await asyncio.sleep(delay)
            
            raise last_exception
        return wrapper
    return decorator


class RuleBasedSQLGenerator:
    """ê·œì¹™ ê¸°ë°˜ SQL ìƒì„±ê¸°"""
    
    def __init__(self):
        self.query_templates = {
            "simple_query": "SELECT * FROM {table} WHERE 1=1 {conditions} LIMIT {limit}",
            "filtering": "SELECT * FROM {table} WHERE {conditions} LIMIT {limit}",
            "aggregation": "SELECT {aggregation} FROM {table} WHERE {conditions}",
            "join": "SELECT * FROM {main_table} JOIN {join_table} ON {join_condition} WHERE {conditions} LIMIT {limit}"
        }
        
        self.entity_to_column_mapping = {
            "customer_names": "name",
            "dates": "created_at", 
            "product_names": "product_type",
            "amounts": "amount",
            "locations": "location"
        }
    
    async def generate_sql(self, intent_result: ClassificationResultDict) -> SQLGenerationResult:
        """ê·œì¹™ ê¸°ë°˜ SQL ìƒì„±"""
        try:
            query_type = intent_result["query_type"]["main_type"]
            entities = intent_result["entities"]
            
            # ê¸°ë³¸ í…Œì´ë¸” ê²°ì •
            main_table = "customers"  # ê¸°ë³¸ê°’
            
            # ì¿¼ë¦¬ íƒ€ì…ë³„ SQL ìƒì„±
            if query_type == "aggregation":
                sql, params = self._generate_aggregation_sql(entities)
            elif query_type == "filtering":
                sql, params = self._generate_filtering_sql(entities)
            elif query_type == "join":
                sql, params = self._generate_join_sql(entities)
            else:  # simple_query
                sql, params = self._generate_simple_sql(entities)
            
            return SQLGenerationResult(
                sql=sql,
                parameters=params,
                explanation=f"ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ëœ {query_type} ì¿¼ë¦¬",
                confidence=0.7,
                complexity_score=0.5,
                generation_method="rule_based"
            )
            
        except Exception as e:
            logger.error(f"ê·œì¹™ ê¸°ë°˜ SQL ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def _generate_aggregation_sql(self, entities: Dict[str, List[str]]) -> Tuple[str, Dict[str, Any]]:
        """ì§‘ê³„ ì¿¼ë¦¬ ìƒì„±"""
        aggregation = "COUNT(*)"
        table = "customers"
        conditions = []
        params = {}
        
        # ì—”í‹°í‹°ì—ì„œ ì¡°ê±´ ì¶”ì¶œ
        for entity_type, values in entities.items():
            if entity_type == "dates" and values:
                conditions.append("created_at >= %(start_date)s")
                params["start_date"] = "2024-05-01"  # ê°„ë‹¨í•œ ì˜ˆì‹œ
        
        where_clause = " AND ".join(conditions) if conditions else "1=1"
        sql = f"SELECT {aggregation} FROM {table} WHERE {where_clause}"
        
        return sql, params
    
    def _generate_filtering_sql(self, entities: Dict[str, List[str]]) -> Tuple[str, Dict[str, Any]]:
        """í•„í„°ë§ ì¿¼ë¦¬ ìƒì„±"""
        table = "customers"
        conditions = []
        params = {}
        
        # ì—”í‹°í‹°ì—ì„œ ì¡°ê±´ ì¶”ì¶œ
        for entity_type, values in entities.items():
            if entity_type == "customer_names" and values:
                conditions.append("name = %(customer_name)s")
                params["customer_name"] = values[0]
            elif entity_type == "dates" and values:
                conditions.append("created_at >= %(start_date)s")
                params["start_date"] = "2024-05-01"
        
        where_clause = " AND ".join(conditions) if conditions else "1=1"
        sql = f"SELECT * FROM {table} WHERE {where_clause} LIMIT 100"
        
        return sql, params
    
    def _generate_simple_sql(self, entities: Dict[str, List[str]]) -> Tuple[str, Dict[str, Any]]:
        """ë‹¨ìˆœ ì¡°íšŒ ì¿¼ë¦¬ ìƒì„±"""
        return "SELECT * FROM customers LIMIT 100", {}
    
    def _generate_join_sql(self, entities: Dict[str, List[str]]) -> Tuple[str, Dict[str, Any]]:
        """ì¡°ì¸ ì¿¼ë¦¬ ìƒì„±"""
        sql = """
        SELECT c.*, m.content 
        FROM customers c 
        LEFT JOIN memos m ON c.id = m.customer_id 
        WHERE 1=1 
        LIMIT 100
        """
        return sql.strip(), {}


class LCELSQLPipeline:
    """LCEL ê¸°ë°˜ ê³ ê¸‰ SQL ìƒì„± íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        """íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        self.llm_manager = LLMClientManager()
        self.chat_client = self.llm_manager.chat_client
        self.rule_generator = RuleBasedSQLGenerator()
        self.metrics_cache: Dict[str, PipelineMetrics] = {}
        
        # ê¸°ë³¸ ì¬ì‹œë„ ì„¤ì •
        self.default_retry_config = RetryConfig()
        
        # LCEL ì²´ì¸ë“¤ ì´ˆê¸°í™”
        self._init_chains()
        
        logger.info("âœ… LCELSQLPipeline ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _init_chains(self):
        """LCEL ì²´ì¸ë“¤ ì´ˆê¸°í™”"""
        
        # 1. ì˜ë„ ë¶„ì„ ì²´ì¸
        self.intent_chain = self._create_intent_chain()
        
        # 2. LLM SQL ìƒì„± ì²´ì¸
        self.llm_sql_chain = self._create_llm_sql_chain()
        
        # 3. ê·œì¹™ ê¸°ë°˜ SQL ìƒì„± ì²´ì¸
        self.rule_sql_chain = self._create_rule_sql_chain()
        
        # 4. SQL ê²€ì¦ ì²´ì¸
        self.validation_chain = self._create_validation_chain()
        
        # 5. Fallback ì²´ì¸ (LLM ì‹¤íŒ¨ ì‹œ ê·œì¹™ ê¸°ë°˜)
        self.fallback_chain = RunnableWithFallbacks(
            runnable=self.llm_sql_chain,
            fallbacks=[self.rule_sql_chain]
        )
        
        # 6. í•˜ì´ë¸Œë¦¬ë“œ ì²´ì¸ (ë³‘ë ¬ ì‹¤í–‰)
        self.hybrid_chain = self._create_hybrid_chain()
        
        # 7. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì²´ì¸
        self.pipeline_chain = self._create_pipeline_chain()
    
    def _create_intent_chain(self):
        """ì˜ë„ ë¶„ì„ ì²´ì¸ ìƒì„±"""
        async def analyze_intent(inputs: Dict[str, Any]) -> Dict[str, Any]:
            query = inputs["query"]
            
            # í•œêµ­ì–´ ì˜ë„ ë¶„ë¥˜ê¸° ì‹¤í–‰
            intent_result = await korean_intent_classifier.classify(query)
            
            return {
                **inputs,
                "intent_analysis": intent_result
            }
        
        return RunnableLambda(analyze_intent).with_config(
            RunnableConfig(run_name="intent_analysis")
        )
    
    def _create_llm_sql_chain(self):
        """LLM SQL ìƒì„± ì²´ì¸"""
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
        async def create_sql_prompt(inputs: Dict[str, Any]) -> Dict[str, Any]:
            query = inputs["query"]
            intent_analysis = inputs["intent_analysis"]
            context = inputs.get("context", {})
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt_text = await nl_prompt_manager.generate_sql_generation_prompt(
                query, intent_analysis, context
            )
            
            return {"prompt": prompt_text}
        
        # ê²°ê³¼ íŒŒì‹± í•¨ìˆ˜
        def parse_sql_result(response: str) -> SQLGenerationResult:
            try:
                # JSON íŒŒì‹± ì‹œë„
                import json
                parsed = json.loads(response)
                return SQLGenerationResult(**parsed)
            except (json.JSONDecodeError, ValueError):
                # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ íŒŒì‹±
                return SQLGenerationResult(
                    sql=response.strip(),
                    explanation="LLMì—ì„œ ìƒì„±ëœ SQL ì¿¼ë¦¬",
                    confidence=0.8,
                    generation_method="llm"
                )
        
        # LLM í˜¸ì¶œ ì²´ì¸
        llm_chain = (
            RunnableLambda(create_sql_prompt)
            | RunnableLambda(lambda x: x["prompt"])
            | self.chat_client 
            | StrOutputParser()
            | RunnableLambda(parse_sql_result)
        )
        
        return llm_chain.with_config(
            RunnableConfig(run_name="llm_sql_generation")
        )
    
    def _create_rule_sql_chain(self):
        """ê·œì¹™ ê¸°ë°˜ SQL ìƒì„± ì²´ì¸"""
        async def generate_rule_sql(inputs: Dict[str, Any]) -> SQLGenerationResult:
            intent_analysis = inputs["intent_analysis"]
            result = await self.rule_generator.generate_sql(intent_analysis)
            result.generation_method = "rule_based"
            return result
        
        return RunnableLambda(generate_rule_sql).with_config(
            RunnableConfig(run_name="rule_sql_generation")
        )
    
    def _create_validation_chain(self):
        """SQL ê²€ì¦ ì²´ì¸"""
        async def validate_sql(sql_result: SQLGenerationResult) -> SQLGenerationResult:
            try:
                # SQL ë³´ì•ˆ ê²€ì¦
                is_safe = await sql_validator.validate_query_safety(sql_result.sql)
                
                if not is_safe:
                    logger.warning(f"ì•ˆì „í•˜ì§€ ì•Šì€ SQL ê°ì§€: {sql_result.sql}")
                    # ì•ˆì „í•˜ì§€ ì•Šì€ ì¿¼ë¦¬ëŠ” ê¸°ë³¸ ì¿¼ë¦¬ë¡œ ëŒ€ì²´
                    sql_result.sql = "SELECT 1 as validation_failed"
                    sql_result.explanation = "ë³´ì•ˆìƒ ì•ˆì „í•˜ì§€ ì•Šì€ ì¿¼ë¦¬ë¡œ ì¸í•´ ê¸°ë³¸ ì¿¼ë¦¬ë¡œ ëŒ€ì²´ë¨"
                    sql_result.confidence = 0.1
                
                return sql_result
                
            except Exception as e:
                logger.error(f"SQL ê²€ì¦ ì‹¤íŒ¨: {e}")
                return sql_result
        
        return RunnableLambda(validate_sql).with_config(
            RunnableConfig(run_name="sql_validation")
        )
    
    def _create_hybrid_chain(self):
        """í•˜ì´ë¸Œë¦¬ë“œ ì²´ì¸ (LLMê³¼ ê·œì¹™ ê¸°ë°˜ ë³‘ë ¬ ì‹¤í–‰)"""
        return RunnableParallel({
            "llm_result": self.llm_sql_chain,
            "rule_result": self.rule_sql_chain
        }).with_config(
            RunnableConfig(run_name="hybrid_generation")
        )
    
    def _create_pipeline_chain(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì²´ì¸"""
        
        # ì „ëµë³„ SQL ìƒì„± ë¶„ê¸°
        def select_generation_strategy(inputs: Dict[str, Any]):
            strategy = inputs.get("strategy", ExecutionStrategy.LLM_FIRST)
            
            if strategy == ExecutionStrategy.LLM_ONLY:
                return self.llm_sql_chain
            elif strategy == ExecutionStrategy.RULE_ONLY:
                return self.rule_sql_chain  
            elif strategy == ExecutionStrategy.HYBRID:
                return self.hybrid_chain
            else:  # LLM_FIRST ë˜ëŠ” RULE_FIRST
                return self.fallback_chain
        
        # íŒŒì´í”„ë¼ì¸ êµ¬ì„±
        pipeline = (
            self.intent_chain
            | RunnableBranch(
                (lambda x: x.get("strategy") == ExecutionStrategy.LLM_ONLY, self.llm_sql_chain),
                (lambda x: x.get("strategy") == ExecutionStrategy.RULE_ONLY, self.rule_sql_chain),
                (lambda x: x.get("strategy") == ExecutionStrategy.HYBRID, self.hybrid_chain),
                self.fallback_chain  # ê¸°ë³¸ê°’
            )
            | self.validation_chain
        )
        
        return pipeline.with_config(
            RunnableConfig(run_name="full_pipeline")
        )
    
    @trace_llm_call("lcel_sql_pipeline_generate", metadata={"version": "2.0"})
    async def generate_sql(
        self, 
        request: EnhancedSQLGenerationRequest,
        stream_queue: Optional[asyncio.Queue] = None
    ) -> EnhancedSQLPipelineResponse:
        """
        ê³ ê¸‰ SQL ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            request: SQL ìƒì„± ìš”ì²­
            stream_queue: ìŠ¤íŠ¸ë¦¬ë°ìš© í (ì„ íƒì )
            
        Returns:
            EnhancedSQLPipelineResponse: íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼
        """
        
        start_time = time.time()
        metrics = PipelineMetrics(
            stage_timings={},
            total_duration=0.0,
            retry_counts={},
            fallback_used=False,
            llm_calls_count=0,
            cache_hits=0,
            success=False
        )
        
        try:
            logger.info(f"ğŸš€ LCEL SQL íŒŒì´í”„ë¼ì¸ ì‹œì‘: {request.query} (ì „ëµ: {request.strategy})")
            
            # ì¬ì‹œë„ ì„¤ì •
            retry_config = request.retry_config or self.default_retry_config
            
            # ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ì„¤ì •
            callbacks = []
            if request.enable_streaming and stream_queue:
                streaming_callback = StreamingCallbackHandler(stream_queue)
                callbacks.append(streaming_callback)
            
            # LangSmith ì½œë°± ì¶”ê°€
            langsmith_callbacks = langsmith_manager.get_callbacks("lcel-sql-pipeline")
            callbacks.extend(langsmith_callbacks)
            
            # íŒŒì´í”„ë¼ì¸ ì…ë ¥ ì¤€ë¹„
            pipeline_input = {
                "query": request.query,
                "context": request.context or {},
                "strategy": request.strategy
            }
            
            # ì¬ì‹œë„ ë¡œì§ê³¼ í•¨ê»˜ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            @exponential_backoff_retry(retry_config)
            async def execute_with_retry():
                config = RunnableConfig(callbacks=callbacks)
                return await self.pipeline_chain.ainvoke(pipeline_input, config)
            
            # íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ì‹¤í–‰
            try:
                result = await asyncio.wait_for(
                    execute_with_retry(),
                    timeout=request.timeout_seconds
                )
            except asyncio.TimeoutError:
                raise Exception(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼: {request.timeout_seconds}ì´ˆ")
            
            # ê²°ê³¼ ì²˜ë¦¬
            if request.strategy == ExecutionStrategy.HYBRID:
                # í•˜ì´ë¸Œë¦¬ë“œ ì „ëµì˜ ê²½ìš° ìµœì  ê²°ê³¼ ì„ íƒ
                llm_result = result["llm_result"]
                rule_result = result["rule_result"]
                
                # ì‹ ë¢°ë„ ê¸°ë°˜ ì„ íƒ
                sql_result = llm_result if llm_result.confidence > rule_result.confidence else rule_result
                sql_result.generation_method = "hybrid"
                
            else:
                sql_result = result
            
            # ì˜ë„ ë¶„ì„ ê²°ê³¼ëŠ” ë³„ë„ë¡œ ì¶”ì¶œí•´ì•¼ í•¨
            # (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì²´ì¸ì˜ ì¤‘ê°„ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ë¡œì§ í•„ìš”)
            intent_analysis = await korean_intent_classifier.classify(request.query)
            
            # ë©”íŠ¸ë¦­ ê³„ì‚°
            metrics.total_duration = time.time() - start_time
            metrics.success = True
            
            response = EnhancedSQLPipelineResponse(
                intent_analysis=intent_analysis,
                sql_result=sql_result,
                success=True,
                metrics={
                    "total_duration": metrics.total_duration,
                    "strategy_used": request.strategy,
                    "generation_method": sql_result.generation_method
                }
            )
            
            logger.info(f"âœ… LCEL SQL íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {metrics.total_duration:.2f}ì´ˆ")
            return response
            
        except Exception as e:
            metrics.total_duration = time.time() - start_time
            metrics.success = False
            metrics.error_message = str(e)
            
            logger.error(f"âŒ LCEL SQL íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            
            # ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
            return EnhancedSQLPipelineResponse(
                intent_analysis={"query_type": {"main_type": "simple_query", "confidence": 0.1}, "entities": {}, "intent_keywords": [], "complexity_score": 0.0},
                sql_result=SQLGenerationResult(
                    sql="SELECT 1 as pipeline_error", 
                    explanation=f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}",
                    generation_method="error_fallback"
                ),
                success=False,
                error_message=str(e),
                metrics={
                    "total_duration": metrics.total_duration,
                    "error": str(e)
                }
            )
    
    async def generate_sql_streaming(
        self, 
        request: EnhancedSQLGenerationRequest
    ) -> AsyncIterator[Dict[str, Any]]:
        """
        ìŠ¤íŠ¸ë¦¬ë° SQL ìƒì„±
        
        Args:
            request: SQL ìƒì„± ìš”ì²­ (enable_streaming=True ì„¤ì •)
            
        Yields:
            Dict[str, Any]: ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ë“¤
        """
        
        # ìŠ¤íŠ¸ë¦¬ë° í ìƒì„±
        stream_queue = asyncio.Queue()
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline_task = asyncio.create_task(
            self.generate_sql(request, stream_queue)
        )
        
        try:
            # ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ì „ì†¡
            while True:
                try:
                    # íì—ì„œ ì´ë²¤íŠ¸ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
                    event = await asyncio.wait_for(stream_queue.get(), timeout=1.0)
                    yield event
                    
                    # íŒŒì´í”„ë¼ì¸ ì™„ë£Œ í™•ì¸
                    if event.get("type") == "pipeline_complete":
                        break
                        
                except asyncio.TimeoutError:
                    # íŒŒì´í”„ë¼ì¸ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                    if pipeline_task.done():
                        break
                    continue
            
            # ìµœì¢… ê²°ê³¼ ì „ì†¡
            final_result = await pipeline_task
            yield {
                "type": "pipeline_complete",
                "result": final_result.model_dump(),
                "timestamp": time.time()
            }
            
        except Exception as e:
            logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            yield {
                "type": "error",
                "error": str(e),
                "timestamp": time.time()
            }
        finally:
            # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì •ë¦¬
            if not pipeline_task.done():
                pipeline_task.cancel()
                try:
                    await pipeline_task
                except asyncio.CancelledError:
                    pass


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
lcel_sql_pipeline = LCELSQLPipeline()